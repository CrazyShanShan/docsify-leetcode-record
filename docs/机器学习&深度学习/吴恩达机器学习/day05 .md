# 6 Logistic Regression

## 6.1 Classification

**discrete 离散** <img src="../../pictures/ML6-1.1.png" alt="image-20211027130718469" style="zoom:50%;" />

![image-20211027131201455](../../pictures/ML6-1.2.png)

## 6.2 Hypothesis Representation

<img src="../../pictures/ML6-2.1.png" alt="image-20211027131625253" style="zoom:50%;" />

<img src="../../pictures/ML6-2.2.png" alt="image-20211027132125638" style="zoom:50%;" />

## 6.3 Decision boundary

<img src="../../pictures/ML6-3.1.png" alt="image-20211027133311712" style="zoom:50%;" />

<img src="../../pictures/ML6-3.2.png" alt="image-20211027133708385" style="zoom:50%;" />

## 6.4 Cost function

**optimization: 优化**

<img src="../../pictures/ML6-4.1.png" alt="image-20211027134358381" style="zoom:50%;" />

**The interpretation of this cost function is that this is the cost I wany my learning algorithm to have to pay, if it outputs that value if its prediction is H of x and the actual label was y**

<img src="../../pictures/ML6-4.2.png" alt="image-20211027135130403" style="zoom:50%;" />

<img src="../../pictures/ML6-4.3.png" alt="image-20211027142150409" style="zoom:50%;" />

## 6.5 Simplified cost function and gradient descent

<img src="../../pictures/ML6-5.1.png" alt="image-20211027151848643" style="zoom:50%;" />

**this formula can be derived from statistics using the principle of maximum likelihood estimation**

<img src="../../pictures/ML6-5.2.png" alt="image-20211027152558253" style="zoom:50%;" />

## 6.6 Advanced optimization

<img src="../../pictures/ML6-6.1.png" alt="image-20211027153435927" style="zoom:50%;" />

<img src="../../pictures/ML6-6.2.png" alt="image-20211027154156207" style="zoom:50%;" />

<img src="../../pictures/ML6-6.3.png" alt="image-20211027154510015" style="zoom:50%;" />

## 6.7 Multi-class classification: One - vs - all

<img src="../../pictures/ML6-7.1.png" alt="image-20211027155238030" style="zoom:50%;" />

<img src="../../pictures/ML6-7.2.png" alt="image-20211027155756452" style="zoom:50%;" />















